{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# IMPORTS=\n",
    "import pandas as pd\n",
    "\n",
    "# PYTORCH=\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# MY DATASET=\n",
    "from src import ChestXrayDataset as CXD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = \"src/data/input/256x256/\"\n",
    "train_df = pd.read_csv(data_dir + \"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Join rows with on image_id, and keep the class_id that is the most frequent:\n",
    "df_ = train_df.groupby(\"image_id\")[\"class_id\"].apply(lambda x: x.value_counts().index[0]).reset_index()\n",
    "# Remove the class_id column from the original dataframe:\n",
    "train_df.drop(\"class_id\", axis=1, inplace=True)\n",
    "# In the train_df, merge the rows with the same image_id, and keep the first row:\n",
    "train_df = train_df.groupby(\"image_id\").first().reset_index()\n",
    "# Merge the original dataframe with first jointure:\n",
    "merge_df = pd.merge(train_df, df_, on=[\"image_id\"])\n",
    "# Save in a .csv file\n",
    "merge_df.to_csv(data_dir + \"train_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### PYTORCH CHEST-XRAY DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create the dataset:\n",
    "data_dir = \"src/data/input/256x256/\"\n",
    "train_df = pd.read_csv(data_dir + \"train_clean.csv\")\n",
    "\n",
    "# Transformation pipeline:\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # Normalize the image\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create the dataset:\n",
    "dataset = CXD.ChestXrayDataset(csv_file=\"train_clean.csv\", data_dir=data_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### TRAIN/VALIDATION SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset into train and validation:\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create the dataloaders:\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(\"Number of train images: \", len(train_dataset))\n",
    "print(\"Number of validation images: \", len(val_dataset))\n",
    "print(\"Number of batches: \", len(train_loader))\n",
    "for i, (images, labels) in enumerate(train_loader):\n",
    "    print(\"Images shape: \", images.shape)\n",
    "    print(\"Labels shape: \", labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Use GPU if available:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.has_mps else \"cpu\")\n",
    "\n",
    "# Define the model:\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_classes = 15\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function and the optimizer:\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    model.train()   # Set the model to training mode\n",
    "    print(\"Epoch: \", epoch)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        if i % 10 == 0:\n",
    "            print(\"Batch: \"+str(i)+\" began.\")\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()     # Weight update\n",
    "        optimizer.step()    # Gradient update\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        train_correct += torch.sum(preds == labels.data).sum().item()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "    train_acc = train_correct / len(train_dataset)\n",
    "    train_loss = train_loss / len(train_dataset)\n",
    "    print(\"Epoch: {}/{}...\".format(epoch + 1, num_epochs),\n",
    "          \"Training Loss: {:.4f}...\".format(train_loss),\n",
    "          \"Training Accuracy: {:.4f}\".format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Test the model on the validation set:\n",
    "model.eval()\n",
    "val_loss = 0.0\n",
    "val_correct = 0\n",
    "for i, (images, labels) in enumerate(val_loader):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    val_loss += loss.item() * images.size(0)\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "    val_correct += torch.sum(preds == labels.data).sum().item()\n",
    "val_acc = val_correct / len(val_dataset)\n",
    "val_loss = val_loss / len(val_dataset)\n",
    "print(\"Validation Loss: {:.4f}...\".format(val_loss),\n",
    "      \"Validation Accuracy: {:.4f}\".format(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save the model:\n",
    "# torch.save(model.state_dict(), \"src/data/output/model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
